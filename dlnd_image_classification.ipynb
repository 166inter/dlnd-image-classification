{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 1:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 1005, 1: 974, 2: 1032, 3: 1016, 4: 999, 5: 937, 6: 1030, 7: 1001, 8: 1025, 9: 981}\n",
      "First 20 Labels: [6, 9, 9, 4, 1, 1, 2, 7, 8, 3, 4, 7, 7, 2, 9, 9, 9, 3, 2, 6]\n",
      "\n",
      "Example of Image 5:\n",
      "Image - Min Value: 0 Max Value: 252\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 1 Name: automobile\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7674716ba8>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 1\n",
    "sample_id = 5\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "[[[[ 0.97647059  0.09411765  0.06666667]\n",
      "   [ 0.71372549  0.24705882  0.32156863]\n",
      "   [ 0.42352941  0.88627451  0.16470588]\n",
      "   ..., \n",
      "   [ 0.32941176  0.72156863  0.75294118]\n",
      "   [ 0.72156863  0.58039216  0.09411765]\n",
      "   [ 0.16470588  0.44705882  0.54117647]]\n",
      "\n",
      "  [[ 0.57647059  0.99607843  0.62745098]\n",
      "   [ 0.94901961  0.58039216  0.35294118]\n",
      "   [ 0.41176471  0.35686275  0.08235294]\n",
      "   ..., \n",
      "   [ 0.64313725  0.70588235  0.11764706]\n",
      "   [ 0.15294118  0.58431373  0.37254902]\n",
      "   [ 0.45490196  0.47843137  0.09803922]]\n",
      "\n",
      "  [[ 0.54901961  0.65098039  0.56862745]\n",
      "   [ 0.60392157  0.38431373  0.61960784]\n",
      "   [ 0.96862745  0.44313725  0.17254902]\n",
      "   ..., \n",
      "   [ 0.71372549  0.00392157  0.64705882]\n",
      "   [ 0.17254902  0.          0.89803922]\n",
      "   [ 0.21568627  0.90196078  0.56470588]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.47843137  0.4         0.71764706]\n",
      "   [ 0.94901961  0.66666667  0.78039216]\n",
      "   [ 0.22745098  0.64313725  0.95294118]\n",
      "   ..., \n",
      "   [ 0.0627451   0.90588235  0.98039216]\n",
      "   [ 0.75686275  0.49803922  0.45882353]\n",
      "   [ 0.91372549  0.47058824  0.55294118]]\n",
      "\n",
      "  [[ 0.71372549  0.85098039  0.52156863]\n",
      "   [ 0.37647059  0.6         0.29019608]\n",
      "   [ 0.11372549  0.15686275  0.72156863]\n",
      "   ..., \n",
      "   [ 0.88627451  0.58039216  0.15294118]\n",
      "   [ 0.17254902  0.78823529  0.38823529]\n",
      "   [ 0.93333333  0.21568627  0.14509804]]\n",
      "\n",
      "  [[ 0.76862745  0.6745098   0.3254902 ]\n",
      "   [ 0.80392157  0.27843137  0.24313725]\n",
      "   [ 0.42745098  0.66666667  0.04705882]\n",
      "   ..., \n",
      "   [ 0.17254902  0.04705882  0.52156863]\n",
      "   [ 0.42352941  0.42352941  0.01960784]\n",
      "   [ 0.19607843  0.45098039  0.5372549 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.19607843  0.64705882  0.77647059]\n",
      "   [ 0.23921569  0.6745098   0.43529412]\n",
      "   [ 0.84705882  0.12156863  0.44313725]\n",
      "   ..., \n",
      "   [ 0.61960784  0.54509804  0.23137255]\n",
      "   [ 0.76862745  0.79215686  0.76470588]\n",
      "   [ 0.10196078  0.24705882  0.1372549 ]]\n",
      "\n",
      "  [[ 0.32941176  0.45882353  0.69411765]\n",
      "   [ 0.96470588  0.78431373  0.80392157]\n",
      "   [ 0.30980392  0.00392157  0.89411765]\n",
      "   ..., \n",
      "   [ 0.83529412  0.45490196  0.22745098]\n",
      "   [ 0.16862745  0.98039216  0.43137255]\n",
      "   [ 0.83529412  0.48235294  0.22745098]]\n",
      "\n",
      "  [[ 0.89019608  0.56470588  0.08235294]\n",
      "   [ 0.04705882  0.83137255  0.90980392]\n",
      "   [ 0.82745098  0.08235294  0.42745098]\n",
      "   ..., \n",
      "   [ 0.21176471  0.09803922  0.95294118]\n",
      "   [ 0.90196078  0.81960784  0.17254902]\n",
      "   [ 0.70588235  0.89803922  0.17254902]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.07058824  0.21176471  0.83529412]\n",
      "   [ 0.03529412  0.89803922  0.98823529]\n",
      "   [ 0.43529412  0.55294118  0.78039216]\n",
      "   ..., \n",
      "   [ 0.53333333  0.61960784  0.74901961]\n",
      "   [ 0.41176471  0.60392157  0.3372549 ]\n",
      "   [ 0.31764706  0.91764706  0.76470588]]\n",
      "\n",
      "  [[ 0.1372549   0.33333333  0.41960784]\n",
      "   [ 0.21176471  0.          0.59607843]\n",
      "   [ 0.8         0.83137255  0.35294118]\n",
      "   ..., \n",
      "   [ 0.71372549  0.07843137  0.00784314]\n",
      "   [ 0.68235294  0.4         0.68627451]\n",
      "   [ 0.5372549   0.75294118  0.54901961]]\n",
      "\n",
      "  [[ 0.30196078  0.16470588  0.69019608]\n",
      "   [ 0.81176471  0.37647059  0.38039216]\n",
      "   [ 0.21960784  0.54901961  0.4745098 ]\n",
      "   ..., \n",
      "   [ 0.69803922  0.24705882  0.89411765]\n",
      "   [ 0.75294118  0.89411765  0.12156863]\n",
      "   [ 0.03921569  0.8         0.42745098]]]\n",
      "\n",
      "\n",
      " [[[ 0.35294118  0.36470588  0.27843137]\n",
      "   [ 0.53333333  0.17254902  0.83137255]\n",
      "   [ 0.85098039  0.11764706  0.32156863]\n",
      "   ..., \n",
      "   [ 0.01176471  0.09411765  0.2745098 ]\n",
      "   [ 0.94901961  0.75294118  0.70588235]\n",
      "   [ 0.22352941  0.00784314  0.3254902 ]]\n",
      "\n",
      "  [[ 0.33333333  0.59215686  0.53333333]\n",
      "   [ 0.05882353  0.88235294  0.39215686]\n",
      "   [ 0.37647059  0.46666667  0.50196078]\n",
      "   ..., \n",
      "   [ 0.58823529  0.13333333  0.23529412]\n",
      "   [ 0.1254902   0.60392157  0.5254902 ]\n",
      "   [ 0.25882353  0.55294118  0.48627451]]\n",
      "\n",
      "  [[ 0.61176471  0.39607843  1.        ]\n",
      "   [ 0.61176471  0.30588235  0.51764706]\n",
      "   [ 0.88235294  0.80784314  0.31764706]\n",
      "   ..., \n",
      "   [ 0.12941176  0.33333333  0.05882353]\n",
      "   [ 0.49019608  0.59607843  0.82745098]\n",
      "   [ 0.65098039  0.00784314  0.69803922]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.96862745  0.72156863  0.65882353]\n",
      "   [ 0.2627451   0.02745098  0.09019608]\n",
      "   [ 0.66666667  0.81568627  0.22745098]\n",
      "   ..., \n",
      "   [ 0.62352941  0.67843137  0.92156863]\n",
      "   [ 0.34117647  0.38039216  0.10196078]\n",
      "   [ 0.9372549   0.07843137  0.92156863]]\n",
      "\n",
      "  [[ 0.95686275  0.62745098  0.09019608]\n",
      "   [ 0.85098039  0.52941176  0.1372549 ]\n",
      "   [ 0.59607843  0.20784314  0.8627451 ]\n",
      "   ..., \n",
      "   [ 0.09019608  0.65882353  0.1372549 ]\n",
      "   [ 0.90196078  0.42745098  0.62745098]\n",
      "   [ 0.59607843  0.25490196  0.69019608]]\n",
      "\n",
      "  [[ 0.51764706  0.84313725  0.93333333]\n",
      "   [ 0.90980392  0.34901961  0.00784314]\n",
      "   [ 0.37254902  0.13333333  0.23529412]\n",
      "   ..., \n",
      "   [ 0.54117647  0.79607843  0.46666667]\n",
      "   [ 0.69803922  0.37254902  0.81960784]\n",
      "   [ 0.0745098   0.36078431  0.71372549]]]\n",
      "\n",
      "\n",
      " ..., \n",
      " [[[ 0.90588235  0.01176471  0.98431373]\n",
      "   [ 0.65882353  0.99607843  0.50980392]\n",
      "   [ 0.96470588  0.38823529  0.01960784]\n",
      "   ..., \n",
      "   [ 0.56862745  0.28627451  0.25882353]\n",
      "   [ 0.54901961  0.27058824  0.36470588]\n",
      "   [ 0.21568627  0.04313725  0.21568627]]\n",
      "\n",
      "  [[ 0.61960784  0.64705882  0.50980392]\n",
      "   [ 0.71764706  0.81176471  0.15294118]\n",
      "   [ 0.58039216  0.22352941  0.24705882]\n",
      "   ..., \n",
      "   [ 0.61960784  0.0627451   0.46666667]\n",
      "   [ 0.84705882  0.90588235  0.14509804]\n",
      "   [ 0.34117647  0.5254902   0.42352941]]\n",
      "\n",
      "  [[ 0.59607843  0.2745098   0.48627451]\n",
      "   [ 0.20392157  0.6         0.11764706]\n",
      "   [ 0.79607843  0.97254902  0.94901961]\n",
      "   ..., \n",
      "   [ 0.54509804  0.18431373  0.91764706]\n",
      "   [ 0.09411765  0.58039216  0.76078431]\n",
      "   [ 0.70588235  0.18039216  0.94509804]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.54509804  0.37647059  0.07058824]\n",
      "   [ 0.83921569  0.51764706  0.65882353]\n",
      "   [ 1.          0.6627451   0.21176471]\n",
      "   ..., \n",
      "   [ 0.71372549  0.51764706  0.39215686]\n",
      "   [ 0.54117647  0.04705882  0.95294118]\n",
      "   [ 0.19607843  0.96470588  0.07058824]]\n",
      "\n",
      "  [[ 0.44313725  0.10980392  0.70196078]\n",
      "   [ 0.90980392  0.25882353  0.58823529]\n",
      "   [ 0.62352941  0.84705882  0.02745098]\n",
      "   ..., \n",
      "   [ 0.81960784  0.45882353  0.59215686]\n",
      "   [ 0.01568627  0.16470588  0.0745098 ]\n",
      "   [ 0.61568627  0.92156863  0.74117647]]\n",
      "\n",
      "  [[ 0.49411765  0.02352941  0.00784314]\n",
      "   [ 0.23921569  0.12156863  0.03137255]\n",
      "   [ 0.09803922  0.38039216  0.6745098 ]\n",
      "   ..., \n",
      "   [ 0.10196078  0.41176471  0.59607843]\n",
      "   [ 0.09411765  0.42352941  0.80392157]\n",
      "   [ 0.02745098  0.10196078  0.11764706]]]\n",
      "\n",
      "\n",
      " [[[ 0.59607843  0.1254902   0.39607843]\n",
      "   [ 0.09803922  0.6         0.75686275]\n",
      "   [ 0.78039216  0.00392157  0.74901961]\n",
      "   ..., \n",
      "   [ 0.2745098   0.98431373  0.31764706]\n",
      "   [ 0.38431373  0.49411765  0.27058824]\n",
      "   [ 0.55686275  0.05490196  0.21960784]]\n",
      "\n",
      "  [[ 0.21960784  0.29019608  0.45882353]\n",
      "   [ 0.79215686  0.09411765  0.99215686]\n",
      "   [ 0.37254902  0.0627451   0.51764706]\n",
      "   ..., \n",
      "   [ 0.5372549   0.49803922  0.49019608]\n",
      "   [ 0.95294118  0.78039216  0.45882353]\n",
      "   [ 0.52941176  0.43137255  0.40392157]]\n",
      "\n",
      "  [[ 0.98431373  0.87843137  0.20392157]\n",
      "   [ 0.34509804  0.63529412  0.        ]\n",
      "   [ 0.69803922  0.31372549  0.60784314]\n",
      "   ..., \n",
      "   [ 0.09411765  0.45490196  0.43921569]\n",
      "   [ 0.82352941  0.20392157  0.00392157]\n",
      "   [ 0.50196078  0.52941176  0.83137255]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.64313725  0.05882353  0.67058824]\n",
      "   [ 0.6745098   0.19215686  0.16862745]\n",
      "   [ 0.34117647  0.08235294  0.08235294]\n",
      "   ..., \n",
      "   [ 0.39607843  0.43137255  0.71372549]\n",
      "   [ 0.85882353  0.75294118  0.90980392]\n",
      "   [ 0.21960784  0.54509804  0.05098039]]\n",
      "\n",
      "  [[ 0.78039216  0.36470588  0.74509804]\n",
      "   [ 0.83921569  0.7372549   0.4627451 ]\n",
      "   [ 0.50980392  0.24705882  0.00392157]\n",
      "   ..., \n",
      "   [ 0.79607843  0.09411765  0.13333333]\n",
      "   [ 0.01568627  0.45882353  0.5372549 ]\n",
      "   [ 0.78039216  0.96862745  0.41960784]]\n",
      "\n",
      "  [[ 0.09019608  0.01960784  0.30196078]\n",
      "   [ 0.56862745  0.11372549  0.20784314]\n",
      "   [ 0.69411765  0.23529412  0.27058824]\n",
      "   ..., \n",
      "   [ 0.09803922  0.59215686  0.72156863]\n",
      "   [ 0.23137255  0.39215686  0.31372549]\n",
      "   [ 0.14901961  0.57647059  0.00784314]]]\n",
      "\n",
      "\n",
      " [[[ 0.55294118  0.14509804  0.61568627]\n",
      "   [ 0.75686275  0.08235294  0.6627451 ]\n",
      "   [ 0.01176471  0.79607843  0.45098039]\n",
      "   ..., \n",
      "   [ 0.20784314  0.8627451   0.91372549]\n",
      "   [ 0.42745098  0.73333333  0.79215686]\n",
      "   [ 0.14901961  0.61568627  0.92941176]]\n",
      "\n",
      "  [[ 0.37647059  0.14901961  0.78823529]\n",
      "   [ 0.86666667  0.47058824  0.84705882]\n",
      "   [ 0.15294118  0.00392157  0.61960784]\n",
      "   ..., \n",
      "   [ 0.71764706  0.96078431  0.03921569]\n",
      "   [ 0.63529412  0.19215686  0.91764706]\n",
      "   [ 0.41176471  0.36470588  0.31372549]]\n",
      "\n",
      "  [[ 0.2745098   0.58039216  0.0745098 ]\n",
      "   [ 0.85490196  0.45098039  0.38039216]\n",
      "   [ 0.57647059  0.20392157  0.85098039]\n",
      "   ..., \n",
      "   [ 0.4627451   0.98039216  0.4627451 ]\n",
      "   [ 0.66666667  0.66666667  0.36470588]\n",
      "   [ 0.03529412  0.82745098  0.55294118]]\n",
      "\n",
      "  ..., \n",
      "  [[ 0.16862745  0.23529412  0.65882353]\n",
      "   [ 0.26666667  0.59607843  0.10196078]\n",
      "   [ 0.25490196  0.80784314  0.54117647]\n",
      "   ..., \n",
      "   [ 0.45098039  0.29411765  0.88235294]\n",
      "   [ 0.4627451   0.63137255  0.2627451 ]\n",
      "   [ 0.29803922  0.80784314  0.84313725]]\n",
      "\n",
      "  [[ 0.16862745  0.99215686  0.56078431]\n",
      "   [ 0.14901961  0.34901961  0.47843137]\n",
      "   [ 0.64313725  0.8627451   0.03529412]\n",
      "   ..., \n",
      "   [ 0.43529412  0.25882353  0.8627451 ]\n",
      "   [ 0.31764706  0.94901961  0.85490196]\n",
      "   [ 0.89411765  0.60784314  0.47843137]]\n",
      "\n",
      "  [[ 0.97254902  0.51764706  0.59607843]\n",
      "   [ 0.43137255  0.5254902   0.79215686]\n",
      "   [ 0.96470588  0.61960784  0.3372549 ]\n",
      "   ..., \n",
      "   [ 0.89019608  0.23137255  0.92156863]\n",
      "   [ 0.28235294  0.81960784  0.52941176]\n",
      "   [ 0.03529412  0.58823529  0.79607843]]]]\n"
     ]
    }
   ],
   "source": [
    "test_shape = (np.random.choice(range(1000)), 32, 32, 3)\n",
    "test_numbers = np.random.choice(range(256), test_shape)\n",
    "\n",
    "numpy_test_numbers = np.array(test_numbers)\n",
    "max_value = numpy_test_numbers.max()\n",
    "print(max_value)\n",
    "normalized = numpy_test_numbers/255\n",
    "print(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    numpy_test_numbers = np.array(x)\n",
    "    max_value = numpy_test_numbers.max()\n",
    "    print(max_value)\n",
    "    normalized = numpy_test_numbers/255\n",
    "    return normalized\n",
    "    \n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 0 4 0 4 7 2 8 5 0 6 7 3 4 6 3 4 0 6 3 5 1 9 8 1 3 3 2 2 2 1 8 5 4 2 2 3\n",
      " 3 4 8 0 4 6 4 1 3 4 2 6 8 4 3 3 3 5 4 7 9 2 9 4 1 8 2 3 3 8 8 5 7 6 5 0 7\n",
      " 3 0 3 2 5 4 4 7 3 5 9 4 9 3 2 3 2 2 8 9 0 2 2 7 5 4 1 0 5 5 1 5 8 1 5 7 9\n",
      " 1 6 2 1 1 5 1 5 4 0 6 9 5 8 4 1 0 5 4 2 4 3 4 5 1 7 7 8 4 2 1 2 5 4 5 8 5\n",
      " 2 5 0 6 7 7 4 0 9 3 0 1 7 7 4 5 2 9 8 3 4 5 7 4 2 7 2 5 7 5 5 3 8 4 2 3 0\n",
      " 4 1 6 9 2 7 4 5 7 5 2 5 6 4 9 2 6 7 5 4 6 0 6 0 8 9 9 9 5 6 4 1 0 4 1 9 9\n",
      " 0 0 1 0 7 4 4 7 3 0 7 3 0 2 7 1 3 8 9 7 6 0 1 1 2 9 9 6 4 0 8 4 0 7 4 8 3\n",
      " 4 8 1 2 4 0 3 6 0 7 4 8 9 7 5 7 2 7 0 2 4 5 8 0 0 2 5 6 1 9 4 8 2 5 0 1 6\n",
      " 5 9 9 2 8 8 2 8 8 8 6 5 4 2 2 0 9 0 3 4 2 0 3 2 8 3 9 1 6 0 3 7 9 9 9 7 5\n",
      " 1 8 0 4 3 2 1 1 8 5 6 5 1 9 8 9 3 8 8 1 2 8 1 2 5 8 0 3 3 1 2 7 6 5 9 7 3\n",
      " 0 0 6 7 1 9 4 0 9 8 6 4 5 9 1 6 7 7 6 3 2 9 9 9 7 5 4 5 3 4 3 2 9 9 3 7 8\n",
      " 0 4 8 8 0 2 3 7 2 3 5 4 5 8 1 6 3 1 8 0 4 7 5 5 5 5 3 8 4 2 7 6 0 3 3 4 8\n",
      " 8 8 8 1 5 3 5 9 7 1 1 6 6 6 6 0 8 1 6 8 0 8 8 9 6 6 9 7 2 0 7 8 9 0 0 3 5\n",
      " 0 4 0 1 6 7 4 5 5 4 9 0 5 3 9 5 5 8 3 5 8 9 5 6 9 9 2 3 9 3 3 9 3 3 9 2 4\n",
      " 3 7 0 8 5 3 1 5 6 5 9 5 4 0 4 7 5 4 1 2 5 6 5 5 7 9 7 3 4 4 1 7 7 9 5 4 0\n",
      " 9 3 0 9 0 8 6 1 1 8 9 6 3 4 0 3 5 7 3 9 3 7 8 0 9 5 1 6 4 3 4 9 9 7 4 8 8\n",
      " 0 7 7 4 1 4 7 8 0 4 3 5 1 0 3 2 5 7 6 5 8 1 1 9 1 7 7 4 3 9 1 2 4 9 9 9 1\n",
      " 9 6 9 6 1 2 2 1 8 8 5 4 1 8 9 7 6 5 4 6 2 0 6 9 7 1 9 7 3 9 7 1 0 7 1 8 8\n",
      " 5 4 2 3 0 9 0 2 9 1 4 0 5 4 3 1 8 7 7 5 6 8 4 7 0 3 4 0 0 6 0 3 4 9 3 3 6\n",
      " 7 9 5 3 1 8 9 4 1 7 1 2 5 9 1 1 3 0 2 0 2 9 7 3 9 8 2 0 9 0 9 3 8 4 0 0 0\n",
      " 0 5 1 0 8 3 2 1 5 0 1 7 6 6 7 4 9 1 2 9 9 1 4 8 9 1 1 4 3 9 8 0 7 7 7 3 4\n",
      " 3 0 4 0 7 3 6 4 3 3 4 3 5 6 0 6 7 8 3 1 8 5 2 7 5 0 6 1 3 7 6 0 1 2 3 0 8\n",
      " 8 1 2 2]\n",
      "7\n",
      "[7, 0, 4, 0, 4, 7, 2, 8, 5, 0, 6, 7, 3, 4, 6, 3, 4, 0, 6, 3, 5, 1, 9, 8, 1, 3, 3, 2, 2, 2, 1, 8, 5, 4, 2, 2, 3, 3, 4, 8, 0, 4, 6, 4, 1, 3, 4, 2, 6, 8, 4, 3, 3, 3, 5, 4, 7, 9, 2, 9, 4, 1, 8, 2, 3, 3, 8, 8, 5, 7, 6, 5, 0, 7, 3, 0, 3, 2, 5, 4, 4, 7, 3, 5, 9, 4, 9, 3, 2, 3, 2, 2, 8, 9, 0, 2, 2, 7, 5, 4, 1, 0, 5, 5, 1, 5, 8, 1, 5, 7, 9, 1, 6, 2, 1, 1, 5, 1, 5, 4, 0, 6, 9, 5, 8, 4, 1, 0, 5, 4, 2, 4, 3, 4, 5, 1, 7, 7, 8, 4, 2, 1, 2, 5, 4, 5, 8, 5, 2, 5, 0, 6, 7, 7, 4, 0, 9, 3, 0, 1, 7, 7, 4, 5, 2, 9, 8, 3, 4, 5, 7, 4, 2, 7, 2, 5, 7, 5, 5, 3, 8, 4, 2, 3, 0, 4, 1, 6, 9, 2, 7, 4, 5, 7, 5, 2, 5, 6, 4, 9, 2, 6, 7, 5, 4, 6, 0, 6, 0, 8, 9, 9, 9, 5, 6, 4, 1, 0, 4, 1, 9, 9, 0, 0, 1, 0, 7, 4, 4, 7, 3, 0, 7, 3, 0, 2, 7, 1, 3, 8, 9, 7, 6, 0, 1, 1, 2, 9, 9, 6, 4, 0, 8, 4, 0, 7, 4, 8, 3, 4, 8, 1, 2, 4, 0, 3, 6, 0, 7, 4, 8, 9, 7, 5, 7, 2, 7, 0, 2, 4, 5, 8, 0, 0, 2, 5, 6, 1, 9, 4, 8, 2, 5, 0, 1, 6, 5, 9, 9, 2, 8, 8, 2, 8, 8, 8, 6, 5, 4, 2, 2, 0, 9, 0, 3, 4, 2, 0, 3, 2, 8, 3, 9, 1, 6, 0, 3, 7, 9, 9, 9, 7, 5, 1, 8, 0, 4, 3, 2, 1, 1, 8, 5, 6, 5, 1, 9, 8, 9, 3, 8, 8, 1, 2, 8, 1, 2, 5, 8, 0, 3, 3, 1, 2, 7, 6, 5, 9, 7, 3, 0, 0, 6, 7, 1, 9, 4, 0, 9, 8, 6, 4, 5, 9, 1, 6, 7, 7, 6, 3, 2, 9, 9, 9, 7, 5, 4, 5, 3, 4, 3, 2, 9, 9, 3, 7, 8, 0, 4, 8, 8, 0, 2, 3, 7, 2, 3, 5, 4, 5, 8, 1, 6, 3, 1, 8, 0, 4, 7, 5, 5, 5, 5, 3, 8, 4, 2, 7, 6, 0, 3, 3, 4, 8, 8, 8, 8, 1, 5, 3, 5, 9, 7, 1, 1, 6, 6, 6, 6, 0, 8, 1, 6, 8, 0, 8, 8, 9, 6, 6, 9, 7, 2, 0, 7, 8, 9, 0, 0, 3, 5, 0, 4, 0, 1, 6, 7, 4, 5, 5, 4, 9, 0, 5, 3, 9, 5, 5, 8, 3, 5, 8, 9, 5, 6, 9, 9, 2, 3, 9, 3, 3, 9, 3, 3, 9, 2, 4, 3, 7, 0, 8, 5, 3, 1, 5, 6, 5, 9, 5, 4, 0, 4, 7, 5, 4, 1, 2, 5, 6, 5, 5, 7, 9, 7, 3, 4, 4, 1, 7, 7, 9, 5, 4, 0, 9, 3, 0, 9, 0, 8, 6, 1, 1, 8, 9, 6, 3, 4, 0, 3, 5, 7, 3, 9, 3, 7, 8, 0, 9, 5, 1, 6, 4, 3, 4, 9, 9, 7, 4, 8, 8, 0, 7, 7, 4, 1, 4, 7, 8, 0, 4, 3, 5, 1, 0, 3, 2, 5, 7, 6, 5, 8, 1, 1, 9, 1, 7, 7, 4, 3, 9, 1, 2, 4, 9, 9, 9, 1, 9, 6, 9, 6, 1, 2, 2, 1, 8, 8, 5, 4, 1, 8, 9, 7, 6, 5, 4, 6, 2, 0, 6, 9, 7, 1, 9, 7, 3, 9, 7, 1, 0, 7, 1, 8, 8, 5, 4, 2, 3, 0, 9, 0, 2, 9, 1, 4, 0, 5, 4, 3, 1, 8, 7, 7, 5, 6, 8, 4, 7, 0, 3, 4, 0, 0, 6, 0, 3, 4, 9, 3, 3, 6, 7, 9, 5, 3, 1, 8, 9, 4, 1, 7, 1, 2, 5, 9, 1, 1, 3, 0, 2, 0, 2, 9, 7, 3, 9, 8, 2, 0, 9, 0, 9, 3, 8, 4, 0, 0, 0, 0, 5, 1, 0, 8, 3, 2, 1, 5, 0, 1, 7, 6, 6, 7, 4, 9, 1, 2, 9, 9, 1, 4, 8, 9, 1, 1, 4, 3, 9, 8, 0, 7, 7, 7, 3, 4, 3, 0, 4, 0, 7, 3, 6, 4, 3, 3, 4, 3, 5, 6, 0, 6, 7, 8, 3, 1, 8, 5, 2, 7, 5, 0, 6, 1, 3, 7, 6, 0, 1, 2, 3, 0, 8, 8, 1, 2, 2]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "[[0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]]\n",
      "[[0 0 0 ..., 1 0 0]\n",
      " [1 0 0 ..., 0 0 0]\n",
      " [0 0 0 ..., 0 0 0]\n",
      " ..., \n",
      " [0 1 0 ..., 0 0 0]\n",
      " [0 0 1 ..., 0 0 0]\n",
      " [0 0 1 ..., 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor label in range(0, len(test_numbers)):\\n    label = test_numbers[label]\\n    one_hot_array = np.array(len(test_numbers))\\n    for i in range(0,len(test_numbers)):\\n        one_hot_array[i] = np.zeros(10)\\n    for label in range(0, len(test_numbers)):\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "test_shape = np.random.choice(range(1000))\n",
    "test_numbers = np.random.choice(range(10), test_shape)\n",
    "print(test_numbers)\n",
    "print(test_numbers[0])\n",
    "\n",
    "just_list = np.ndarray.tolist(test_numbers)\n",
    "print(just_list)\n",
    "\n",
    "for i in range(0, test_shape):\n",
    "    just_list[i] = [0]*10\n",
    "print(just_list)\n",
    "\n",
    "for i in range(0, test_shape):\n",
    "    just_list[i][test_numbers[i]] = 1  \n",
    "print(just_list)\n",
    "one_hot = np.array(just_list)\n",
    "print(one_hot)\n",
    "'''\n",
    "for label in range(0, len(test_numbers)):\n",
    "    label = test_numbers[label]\n",
    "    one_hot_array = np.array(len(test_numbers))\n",
    "    for i in range(0,len(test_numbers)):\n",
    "        one_hot_array[i] = np.zeros(10)\n",
    "    for label in range(0, len(test_numbers)):\n",
    "'''        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    #print(x)\n",
    "    x_zeros = [0]*len(x)\n",
    "    for i in range(0, len(x)):\n",
    "        x_zeros[i] = [0]*10\n",
    "        x_zeros[i][x[i]] = 1\n",
    "    #print(x_zeros)\n",
    "    \n",
    "    one_hot = np.array(x_zeros)\n",
    "    return one_hot\n",
    "   \n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=(None, image_shape[0], image_shape[1], image_shape[2]), name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    return tf.placeholder(tf.float32, shape=(None, n_classes), name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x = tf.placeholder(tf.float32, shape=None, name='keep_prob')\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dims = x_tensor.get_shape().as_list()\n",
    "    filter_ = tf.Variable(tf.random_normal([conv_ksize[0], conv_ksize[1], dims[3], conv_num_outputs]))\n",
    "    bias = tf.Variable(tf.zeros([conv_num_outputs]))\n",
    "    x_tensor = tf.nn.conv2d(x_tensor, filter_, strides=(1, conv_strides[0], conv_strides[1], 1), padding='SAME')\n",
    "    x_tensor = tf.nn.bias_add(x_tensor, bias)\n",
    "    x_tensor = tf.nn.relu(x_tensor)\n",
    "    \n",
    "    x_tensor = tf.nn.max_pool(x_tensor, [1, pool_ksize[0], pool_ksize[1], 1], strides=(1, pool_strides[0], pool_strides[1], 1), padding='SAME')\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_tensor = tf.contrib.layers.flatten(x_tensor)\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_tensor = tf.contrib.layers.fully_connected(x_tensor, num_outputs=(num_outputs))\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    x_tensor = tf.contrib.layers.fully_connected(x_tensor, num_outputs=(num_outputs))\n",
    "    return x_tensor\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    \n",
    "    num_outputs = 10\n",
    "    x = conv2d_maxpool(x, 32, (2,2), (2,2), (2,2), (2,2))\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    x = flatten(x)\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    x = fully_conn(x,32 )\n",
    "    x = tf.nn.dropout(x, keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    x = output(x, num_outputs)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return x\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    \n",
    "    session.run(optimizer, feed_dict={x: feature_batch, y: label_batch, keep_prob: keep_probability})\n",
    "    \n",
    "    pass\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    #print(session.run(cost, accuracy, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1}))\n",
    "    \n",
    "    loss = session.run(cost, feed_dict={x: feature_batch, y: label_batch, keep_prob: 1.0})\n",
    "    valid_acc = session.run(accuracy, feed_dict={x: valid_features, y: valid_labels, keep_prob: 1.0})\n",
    "    print('Loss: {:>10.4f} Accuracy: {:.6f}'.format(loss,valid_acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 100\n",
    "batch_size = 512\n",
    "keep_probability = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.2573 Accuracy: 0.106400\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.2405 Accuracy: 0.138200\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.2046 Accuracy: 0.143000\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     2.1962 Accuracy: 0.183000\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     2.1719 Accuracy: 0.219000\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     2.1310 Accuracy: 0.252400\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     2.1022 Accuracy: 0.252600\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     2.0826 Accuracy: 0.284800\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     2.0500 Accuracy: 0.289400\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     2.0546 Accuracy: 0.287800\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     2.0028 Accuracy: 0.312000\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.9653 Accuracy: 0.322800\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.9329 Accuracy: 0.345400\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.9004 Accuracy: 0.349800\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.8678 Accuracy: 0.364000\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.8507 Accuracy: 0.368200\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.8158 Accuracy: 0.381600\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.7983 Accuracy: 0.390600\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.7826 Accuracy: 0.392200\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.7583 Accuracy: 0.400600\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.7482 Accuracy: 0.407600\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.7353 Accuracy: 0.409600\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.7031 Accuracy: 0.414000\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.7036 Accuracy: 0.414800\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.6792 Accuracy: 0.416000\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.6727 Accuracy: 0.418600\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     1.6603 Accuracy: 0.417400\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.6301 Accuracy: 0.424400\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     1.6222 Accuracy: 0.429800\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     1.6086 Accuracy: 0.428400\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     1.6217 Accuracy: 0.425800\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     1.5992 Accuracy: 0.427400\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     1.5553 Accuracy: 0.449200\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     1.5270 Accuracy: 0.464800\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     1.5037 Accuracy: 0.465200\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     1.4997 Accuracy: 0.460000\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     1.4627 Accuracy: 0.465600\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     1.4416 Accuracy: 0.469600\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     1.4165 Accuracy: 0.471000\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     1.3881 Accuracy: 0.476800\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.3795 Accuracy: 0.474600\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.3670 Accuracy: 0.485600\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.3635 Accuracy: 0.482400\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.3469 Accuracy: 0.486000\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.3318 Accuracy: 0.480200\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.3167 Accuracy: 0.486000\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.3144 Accuracy: 0.486200\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.2967 Accuracy: 0.483600\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.2904 Accuracy: 0.479800\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.2783 Accuracy: 0.489400\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.2712 Accuracy: 0.487000\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.2609 Accuracy: 0.489800\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.2480 Accuracy: 0.485600\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.2464 Accuracy: 0.488800\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.2432 Accuracy: 0.492400\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.2184 Accuracy: 0.498600\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.2099 Accuracy: 0.500000\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.2258 Accuracy: 0.494400\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.2078 Accuracy: 0.501400\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.2078 Accuracy: 0.503800\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.2052 Accuracy: 0.500400\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.1811 Accuracy: 0.496800\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.2068 Accuracy: 0.496600\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.1878 Accuracy: 0.501200\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.1791 Accuracy: 0.503600\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.1747 Accuracy: 0.503600\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.1828 Accuracy: 0.502400\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.1594 Accuracy: 0.505600\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.1636 Accuracy: 0.500600\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.1442 Accuracy: 0.503800\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.1486 Accuracy: 0.499600\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.1586 Accuracy: 0.497400\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.1497 Accuracy: 0.504000\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     1.1430 Accuracy: 0.501200\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     1.1342 Accuracy: 0.496600\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     1.1204 Accuracy: 0.503200\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     1.1157 Accuracy: 0.502200\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     1.1193 Accuracy: 0.503200\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     1.1029 Accuracy: 0.504800\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     1.0960 Accuracy: 0.504200\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     1.1060 Accuracy: 0.502800\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     1.0924 Accuracy: 0.504000\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     1.1055 Accuracy: 0.507000\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     1.1050 Accuracy: 0.498400\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     1.0881 Accuracy: 0.505600\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     1.0863 Accuracy: 0.504400\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     1.0779 Accuracy: 0.509400\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     1.0802 Accuracy: 0.504400\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     1.0771 Accuracy: 0.508800\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     1.0865 Accuracy: 0.498600\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     1.0640 Accuracy: 0.501000\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     1.0688 Accuracy: 0.505200\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     1.0657 Accuracy: 0.501200\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     1.0436 Accuracy: 0.507600\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     1.0599 Accuracy: 0.501400\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     1.0465 Accuracy: 0.499400\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     1.0397 Accuracy: 0.501000\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     1.0461 Accuracy: 0.499200\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     1.0378 Accuracy: 0.498800\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     1.0202 Accuracy: 0.501400\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss:     2.3025 Accuracy: 0.099800\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss:     2.3022 Accuracy: 0.102200\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss:     2.2597 Accuracy: 0.184200\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss:     2.1746 Accuracy: 0.193200\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss:     2.1417 Accuracy: 0.202800\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss:     2.1645 Accuracy: 0.253000\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss:     2.0687 Accuracy: 0.260000\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss:     2.1049 Accuracy: 0.276800\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss:     2.0203 Accuracy: 0.273200\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss:     1.9961 Accuracy: 0.300600\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss:     2.0683 Accuracy: 0.294000\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss:     1.9710 Accuracy: 0.311200\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss:     1.9667 Accuracy: 0.320400\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss:     1.9227 Accuracy: 0.310000\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss:     1.9097 Accuracy: 0.335800\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss:     1.9734 Accuracy: 0.333000\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss:     1.8288 Accuracy: 0.365000\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss:     1.8116 Accuracy: 0.368400\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss:     1.7711 Accuracy: 0.393000\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss:     1.7533 Accuracy: 0.403600\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss:     1.8306 Accuracy: 0.402600\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss:     1.7459 Accuracy: 0.402800\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss:     1.7074 Accuracy: 0.411400\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss:     1.6990 Accuracy: 0.409800\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss:     1.7047 Accuracy: 0.419800\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss:     1.7833 Accuracy: 0.415400\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss:     1.6480 Accuracy: 0.433600\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss:     1.6544 Accuracy: 0.432400\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss:     1.6556 Accuracy: 0.426400\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss:     1.6729 Accuracy: 0.431600\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss:     1.7478 Accuracy: 0.423400\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss:     1.6256 Accuracy: 0.445600\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss:     1.6037 Accuracy: 0.448200\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss:     1.6108 Accuracy: 0.437600\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss:     1.6280 Accuracy: 0.445800\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss:     1.7010 Accuracy: 0.433800\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss:     1.5863 Accuracy: 0.442000\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss:     1.5786 Accuracy: 0.448000\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss:     1.5967 Accuracy: 0.452400\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss:     1.6253 Accuracy: 0.450400\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss:     1.6882 Accuracy: 0.446600\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss:     1.5451 Accuracy: 0.446400\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss:     1.5381 Accuracy: 0.454000\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss:     1.5666 Accuracy: 0.451800\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss:     1.5932 Accuracy: 0.460200\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss:     1.6707 Accuracy: 0.448000\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss:     1.5432 Accuracy: 0.464000\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss:     1.5332 Accuracy: 0.462400\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss:     1.5450 Accuracy: 0.464400\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss:     1.5698 Accuracy: 0.466200\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss:     1.6449 Accuracy: 0.465000\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss:     1.5262 Accuracy: 0.467400\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss:     1.5061 Accuracy: 0.471600\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss:     1.5301 Accuracy: 0.466600\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss:     1.5491 Accuracy: 0.469400\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss:     1.6320 Accuracy: 0.460200\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss:     1.4992 Accuracy: 0.470600\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss:     1.4900 Accuracy: 0.473000\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss:     1.5184 Accuracy: 0.462800\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss:     1.5334 Accuracy: 0.468600\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss:     1.6212 Accuracy: 0.468600\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss:     1.5182 Accuracy: 0.475600\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss:     1.5082 Accuracy: 0.478200\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss:     1.5143 Accuracy: 0.469400\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss:     1.5259 Accuracy: 0.471600\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss:     1.5937 Accuracy: 0.469200\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss:     1.4902 Accuracy: 0.466400\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss:     1.4864 Accuracy: 0.476800\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss:     1.5092 Accuracy: 0.474000\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss:     1.5093 Accuracy: 0.480600\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss:     1.5863 Accuracy: 0.475600\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss:     1.4746 Accuracy: 0.475400\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss:     1.4624 Accuracy: 0.488000\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss:     1.4979 Accuracy: 0.478800\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss:     1.4965 Accuracy: 0.474000\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss:     1.5791 Accuracy: 0.486600\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss:     1.4706 Accuracy: 0.473000\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss:     1.4517 Accuracy: 0.488200\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss:     1.4803 Accuracy: 0.475400\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss:     1.4806 Accuracy: 0.486000\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss:     1.5619 Accuracy: 0.485800\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss:     1.4571 Accuracy: 0.483200\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss:     1.4468 Accuracy: 0.488000\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss:     1.4721 Accuracy: 0.483800\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss:     1.4884 Accuracy: 0.486800\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss:     1.5534 Accuracy: 0.478000\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss:     1.4356 Accuracy: 0.479000\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss:     1.4386 Accuracy: 0.492800\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss:     1.4691 Accuracy: 0.483000\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss:     1.4799 Accuracy: 0.484800\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss:     1.5477 Accuracy: 0.485800\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss:     1.4545 Accuracy: 0.481200\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss:     1.4376 Accuracy: 0.491400\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss:     1.4755 Accuracy: 0.481600\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss:     1.4693 Accuracy: 0.488200\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss:     1.5334 Accuracy: 0.486600\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss:     1.4414 Accuracy: 0.492000\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss:     1.4278 Accuracy: 0.497600\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss:     1.4505 Accuracy: 0.488200\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss:     1.4627 Accuracy: 0.489200\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss:     1.5437 Accuracy: 0.490600\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss:     1.4306 Accuracy: 0.483200\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss:     1.4261 Accuracy: 0.494600\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss:     1.4351 Accuracy: 0.491200\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss:     1.4493 Accuracy: 0.497600\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss:     1.5289 Accuracy: 0.488600\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss:     1.4026 Accuracy: 0.493200\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss:     1.4060 Accuracy: 0.499800\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss:     1.4271 Accuracy: 0.496800\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss:     1.4193 Accuracy: 0.503200\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss:     1.4836 Accuracy: 0.491200\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss:     1.3430 Accuracy: 0.503000\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss:     1.3123 Accuracy: 0.515600\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss:     1.3027 Accuracy: 0.514400\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss:     1.3046 Accuracy: 0.519000\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss:     1.4079 Accuracy: 0.501600\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss:     1.3103 Accuracy: 0.507000\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss:     1.2675 Accuracy: 0.510400\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss:     1.2636 Accuracy: 0.513200\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss:     1.2969 Accuracy: 0.520000\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss:     1.3763 Accuracy: 0.517000\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss:     1.2824 Accuracy: 0.510400\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss:     1.2474 Accuracy: 0.528800\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss:     1.2398 Accuracy: 0.519200\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss:     1.2706 Accuracy: 0.519000\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss:     1.3686 Accuracy: 0.525000\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss:     1.2829 Accuracy: 0.513800\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss:     1.2285 Accuracy: 0.524600\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss:     1.2305 Accuracy: 0.524800\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss:     1.2526 Accuracy: 0.526800\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss:     1.3559 Accuracy: 0.527000\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss:     1.2644 Accuracy: 0.513200\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss:     1.2162 Accuracy: 0.522400\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss:     1.2280 Accuracy: 0.527600\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss:     1.2480 Accuracy: 0.529400\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss:     1.3534 Accuracy: 0.528800\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss:     1.2506 Accuracy: 0.514600\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss:     1.2163 Accuracy: 0.524400\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss:     1.2397 Accuracy: 0.518200\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss:     1.2359 Accuracy: 0.536600\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss:     1.3319 Accuracy: 0.526800\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss:     1.2299 Accuracy: 0.517600\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss:     1.1914 Accuracy: 0.527600\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss:     1.2485 Accuracy: 0.523800\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss:     1.2385 Accuracy: 0.536800\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss:     1.3284 Accuracy: 0.532600\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss:     1.2318 Accuracy: 0.518000\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss:     1.1857 Accuracy: 0.525800\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss:     1.2153 Accuracy: 0.528200\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss:     1.2419 Accuracy: 0.537400\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss:     1.3198 Accuracy: 0.533400\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss:     1.2163 Accuracy: 0.519600\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss:     1.2126 Accuracy: 0.516800\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss:     1.2392 Accuracy: 0.521800\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss:     1.2271 Accuracy: 0.537800\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss:     1.3154 Accuracy: 0.539600\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss:     1.2087 Accuracy: 0.528200\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss:     1.1883 Accuracy: 0.530000\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss:     1.1961 Accuracy: 0.532000\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss:     1.2067 Accuracy: 0.536200\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss:     1.3135 Accuracy: 0.534600\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss:     1.2035 Accuracy: 0.529400\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss:     1.1598 Accuracy: 0.530600\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss:     1.2202 Accuracy: 0.528800\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss:     1.2174 Accuracy: 0.536800\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss:     1.3123 Accuracy: 0.539600\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss:     1.1989 Accuracy: 0.530000\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss:     1.1623 Accuracy: 0.534800\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss:     1.1951 Accuracy: 0.531000\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss:     1.2048 Accuracy: 0.537400\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss:     1.3109 Accuracy: 0.532000\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss:     1.1908 Accuracy: 0.537000\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss:     1.1437 Accuracy: 0.531600\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss:     1.1998 Accuracy: 0.534600\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss:     1.2001 Accuracy: 0.542000\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss:     1.2947 Accuracy: 0.538800\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss:     1.1646 Accuracy: 0.539000\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss:     1.1442 Accuracy: 0.534000\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss:     1.1995 Accuracy: 0.528600\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss:     1.2026 Accuracy: 0.532400\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss:     1.2849 Accuracy: 0.531600\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss:     1.1562 Accuracy: 0.537800\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss:     1.1565 Accuracy: 0.533600\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss:     1.1895 Accuracy: 0.535800\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss:     1.1933 Accuracy: 0.538600\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss:     1.2875 Accuracy: 0.537400\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss:     1.1561 Accuracy: 0.535600\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss:     1.1249 Accuracy: 0.540200\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss:     1.1750 Accuracy: 0.532600\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss:     1.2049 Accuracy: 0.538200\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss:     1.2713 Accuracy: 0.543800\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss:     1.1428 Accuracy: 0.537400\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss:     1.1213 Accuracy: 0.539000\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss:     1.1766 Accuracy: 0.535400\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss:     1.1971 Accuracy: 0.541800\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss:     1.2674 Accuracy: 0.539200\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss:     1.1547 Accuracy: 0.535200\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss:     1.1071 Accuracy: 0.538600\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss:     1.1594 Accuracy: 0.533400\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss:     1.1876 Accuracy: 0.539200\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss:     1.2618 Accuracy: 0.541600\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss:     1.1424 Accuracy: 0.537600\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss:     1.1104 Accuracy: 0.538400\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss:     1.1636 Accuracy: 0.531200\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss:     1.1833 Accuracy: 0.540000\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss:     1.2699 Accuracy: 0.538400\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss:     1.1410 Accuracy: 0.537400\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss:     1.1082 Accuracy: 0.540800\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss:     1.1768 Accuracy: 0.531800\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss:     1.1824 Accuracy: 0.540400\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss:     1.2659 Accuracy: 0.545000\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss:     1.1420 Accuracy: 0.537600\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss:     1.1245 Accuracy: 0.537800\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss:     1.1479 Accuracy: 0.538200\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss:     1.1784 Accuracy: 0.540200\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss:     1.2533 Accuracy: 0.544600\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss:     1.1284 Accuracy: 0.538400\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss:     1.0991 Accuracy: 0.542000\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss:     1.1583 Accuracy: 0.535800\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss:     1.1772 Accuracy: 0.539800\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss:     1.2496 Accuracy: 0.539600\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss:     1.1280 Accuracy: 0.543400\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss:     1.1190 Accuracy: 0.534000\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss:     1.1457 Accuracy: 0.537200\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss:     1.1709 Accuracy: 0.540400\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss:     1.2466 Accuracy: 0.545000\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss:     1.1342 Accuracy: 0.537200\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss:     1.1235 Accuracy: 0.537400\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss:     1.1436 Accuracy: 0.532400\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss:     1.1591 Accuracy: 0.543000\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss:     1.2381 Accuracy: 0.543600\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss:     1.1126 Accuracy: 0.545800\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss:     1.1208 Accuracy: 0.539600\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss:     1.1357 Accuracy: 0.534600\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss:     1.1665 Accuracy: 0.536600\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss:     1.2478 Accuracy: 0.538400\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss:     1.1129 Accuracy: 0.537400\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss:     1.0935 Accuracy: 0.542200\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss:     1.1400 Accuracy: 0.535800\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss:     1.1510 Accuracy: 0.537200\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss:     1.2283 Accuracy: 0.541200\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss:     1.1361 Accuracy: 0.534000\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss:     1.0899 Accuracy: 0.540600\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss:     1.1253 Accuracy: 0.536200\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss:     1.1474 Accuracy: 0.540400\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss:     1.2364 Accuracy: 0.539000\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss:     1.1006 Accuracy: 0.541000\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss:     1.0939 Accuracy: 0.540000\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss:     1.1202 Accuracy: 0.536600\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss:     1.1600 Accuracy: 0.542600\n",
      "Epoch 51, CIFAR-10 Batch 1:  Loss:     1.2197 Accuracy: 0.542400\n",
      "Epoch 51, CIFAR-10 Batch 2:  Loss:     1.1101 Accuracy: 0.541000\n",
      "Epoch 51, CIFAR-10 Batch 3:  Loss:     1.0892 Accuracy: 0.540200\n",
      "Epoch 51, CIFAR-10 Batch 4:  Loss:     1.1078 Accuracy: 0.533200\n",
      "Epoch 51, CIFAR-10 Batch 5:  Loss:     1.1438 Accuracy: 0.540200\n",
      "Epoch 52, CIFAR-10 Batch 1:  Loss:     1.2056 Accuracy: 0.537400\n",
      "Epoch 52, CIFAR-10 Batch 2:  Loss:     1.1046 Accuracy: 0.534200\n",
      "Epoch 52, CIFAR-10 Batch 3:  Loss:     1.0922 Accuracy: 0.541200\n",
      "Epoch 52, CIFAR-10 Batch 4:  Loss:     1.1098 Accuracy: 0.534400\n",
      "Epoch 52, CIFAR-10 Batch 5:  Loss:     1.1551 Accuracy: 0.538000\n",
      "Epoch 53, CIFAR-10 Batch 1:  Loss:     1.2139 Accuracy: 0.543400\n",
      "Epoch 53, CIFAR-10 Batch 2:  Loss:     1.0888 Accuracy: 0.537400\n",
      "Epoch 53, CIFAR-10 Batch 3:  Loss:     1.0866 Accuracy: 0.536400\n",
      "Epoch 53, CIFAR-10 Batch 4:  Loss:     1.1317 Accuracy: 0.536600\n",
      "Epoch 53, CIFAR-10 Batch 5:  Loss:     1.1411 Accuracy: 0.539800\n",
      "Epoch 54, CIFAR-10 Batch 1:  Loss:     1.2023 Accuracy: 0.541600\n",
      "Epoch 54, CIFAR-10 Batch 2:  Loss:     1.0921 Accuracy: 0.540000\n",
      "Epoch 54, CIFAR-10 Batch 3:  Loss:     1.0694 Accuracy: 0.537800\n",
      "Epoch 54, CIFAR-10 Batch 4:  Loss:     1.0957 Accuracy: 0.535400\n",
      "Epoch 54, CIFAR-10 Batch 5:  Loss:     1.1467 Accuracy: 0.533400\n",
      "Epoch 55, CIFAR-10 Batch 1:  Loss:     1.2107 Accuracy: 0.540800\n",
      "Epoch 55, CIFAR-10 Batch 2:  Loss:     1.0938 Accuracy: 0.541400\n",
      "Epoch 55, CIFAR-10 Batch 3:  Loss:     1.0689 Accuracy: 0.546000\n",
      "Epoch 55, CIFAR-10 Batch 4:  Loss:     1.0961 Accuracy: 0.542600\n",
      "Epoch 55, CIFAR-10 Batch 5:  Loss:     1.1384 Accuracy: 0.543000\n",
      "Epoch 56, CIFAR-10 Batch 1:  Loss:     1.1971 Accuracy: 0.541400\n",
      "Epoch 56, CIFAR-10 Batch 2:  Loss:     1.0932 Accuracy: 0.540400\n",
      "Epoch 56, CIFAR-10 Batch 3:  Loss:     1.0731 Accuracy: 0.542000\n",
      "Epoch 56, CIFAR-10 Batch 4:  Loss:     1.0970 Accuracy: 0.534800\n",
      "Epoch 56, CIFAR-10 Batch 5:  Loss:     1.1360 Accuracy: 0.542400\n",
      "Epoch 57, CIFAR-10 Batch 1:  Loss:     1.2021 Accuracy: 0.540000\n",
      "Epoch 57, CIFAR-10 Batch 2:  Loss:     1.0951 Accuracy: 0.539400\n",
      "Epoch 57, CIFAR-10 Batch 3:  Loss:     1.0787 Accuracy: 0.543600\n",
      "Epoch 57, CIFAR-10 Batch 4:  Loss:     1.0935 Accuracy: 0.541400\n",
      "Epoch 57, CIFAR-10 Batch 5:  Loss:     1.1512 Accuracy: 0.537000\n",
      "Epoch 58, CIFAR-10 Batch 1:  Loss:     1.2069 Accuracy: 0.536800\n",
      "Epoch 58, CIFAR-10 Batch 2:  Loss:     1.0936 Accuracy: 0.542200\n",
      "Epoch 58, CIFAR-10 Batch 3:  Loss:     1.0786 Accuracy: 0.538600\n",
      "Epoch 58, CIFAR-10 Batch 4:  Loss:     1.0811 Accuracy: 0.535600\n",
      "Epoch 58, CIFAR-10 Batch 5:  Loss:     1.1375 Accuracy: 0.542800\n",
      "Epoch 59, CIFAR-10 Batch 1:  Loss:     1.1896 Accuracy: 0.542200\n",
      "Epoch 59, CIFAR-10 Batch 2:  Loss:     1.0888 Accuracy: 0.545400\n",
      "Epoch 59, CIFAR-10 Batch 3:  Loss:     1.0662 Accuracy: 0.542600\n",
      "Epoch 59, CIFAR-10 Batch 4:  Loss:     1.0960 Accuracy: 0.539600\n",
      "Epoch 59, CIFAR-10 Batch 5:  Loss:     1.1389 Accuracy: 0.538400\n",
      "Epoch 60, CIFAR-10 Batch 1:  Loss:     1.1863 Accuracy: 0.539000\n",
      "Epoch 60, CIFAR-10 Batch 2:  Loss:     1.0713 Accuracy: 0.543600\n",
      "Epoch 60, CIFAR-10 Batch 3:  Loss:     1.0754 Accuracy: 0.544600\n",
      "Epoch 60, CIFAR-10 Batch 4:  Loss:     1.0958 Accuracy: 0.542600\n",
      "Epoch 60, CIFAR-10 Batch 5:  Loss:     1.1290 Accuracy: 0.544400\n",
      "Epoch 61, CIFAR-10 Batch 1:  Loss:     1.1943 Accuracy: 0.539200\n",
      "Epoch 61, CIFAR-10 Batch 2:  Loss:     1.0881 Accuracy: 0.534200\n",
      "Epoch 61, CIFAR-10 Batch 3:  Loss:     1.0951 Accuracy: 0.540800\n",
      "Epoch 61, CIFAR-10 Batch 4:  Loss:     1.1037 Accuracy: 0.534200\n",
      "Epoch 61, CIFAR-10 Batch 5:  Loss:     1.1339 Accuracy: 0.541200\n",
      "Epoch 62, CIFAR-10 Batch 1:  Loss:     1.1768 Accuracy: 0.539000\n",
      "Epoch 62, CIFAR-10 Batch 2:  Loss:     1.0773 Accuracy: 0.536400\n",
      "Epoch 62, CIFAR-10 Batch 3:  Loss:     1.0507 Accuracy: 0.541800\n",
      "Epoch 62, CIFAR-10 Batch 4:  Loss:     1.0729 Accuracy: 0.541800\n",
      "Epoch 62, CIFAR-10 Batch 5:  Loss:     1.1190 Accuracy: 0.547200\n",
      "Epoch 63, CIFAR-10 Batch 1:  Loss:     1.1802 Accuracy: 0.542400\n",
      "Epoch 63, CIFAR-10 Batch 2:  Loss:     1.0782 Accuracy: 0.545000\n",
      "Epoch 63, CIFAR-10 Batch 3:  Loss:     1.0650 Accuracy: 0.539000\n",
      "Epoch 63, CIFAR-10 Batch 4:  Loss:     1.0753 Accuracy: 0.539000\n",
      "Epoch 63, CIFAR-10 Batch 5:  Loss:     1.1119 Accuracy: 0.542400\n",
      "Epoch 64, CIFAR-10 Batch 1:  Loss:     1.1800 Accuracy: 0.542000\n",
      "Epoch 64, CIFAR-10 Batch 2:  Loss:     1.0767 Accuracy: 0.545200\n",
      "Epoch 64, CIFAR-10 Batch 3:  Loss:     1.0557 Accuracy: 0.539800\n",
      "Epoch 64, CIFAR-10 Batch 4:  Loss:     1.0729 Accuracy: 0.540400\n",
      "Epoch 64, CIFAR-10 Batch 5:  Loss:     1.1211 Accuracy: 0.545800\n",
      "Epoch 65, CIFAR-10 Batch 1:  Loss:     1.1720 Accuracy: 0.540200\n",
      "Epoch 65, CIFAR-10 Batch 2:  Loss:     1.0738 Accuracy: 0.548600\n",
      "Epoch 65, CIFAR-10 Batch 3:  Loss:     1.0454 Accuracy: 0.541400\n",
      "Epoch 65, CIFAR-10 Batch 4:  Loss:     1.0606 Accuracy: 0.544400\n",
      "Epoch 65, CIFAR-10 Batch 5:  Loss:     1.1174 Accuracy: 0.540800\n",
      "Epoch 66, CIFAR-10 Batch 1:  Loss:     1.1684 Accuracy: 0.542800\n",
      "Epoch 66, CIFAR-10 Batch 2:  Loss:     1.0781 Accuracy: 0.544400\n",
      "Epoch 66, CIFAR-10 Batch 3:  Loss:     1.0530 Accuracy: 0.546400\n",
      "Epoch 66, CIFAR-10 Batch 4:  Loss:     1.0671 Accuracy: 0.536800\n",
      "Epoch 66, CIFAR-10 Batch 5:  Loss:     1.1136 Accuracy: 0.544200\n",
      "Epoch 67, CIFAR-10 Batch 1:  Loss:     1.1671 Accuracy: 0.545800\n",
      "Epoch 67, CIFAR-10 Batch 2:  Loss:     1.0710 Accuracy: 0.543000\n",
      "Epoch 67, CIFAR-10 Batch 3:  Loss:     1.0392 Accuracy: 0.543600\n",
      "Epoch 67, CIFAR-10 Batch 4:  Loss:     1.0738 Accuracy: 0.539600\n",
      "Epoch 67, CIFAR-10 Batch 5:  Loss:     1.1093 Accuracy: 0.550000\n",
      "Epoch 68, CIFAR-10 Batch 1:  Loss:     1.1569 Accuracy: 0.546600\n",
      "Epoch 68, CIFAR-10 Batch 2:  Loss:     1.0598 Accuracy: 0.543600\n",
      "Epoch 68, CIFAR-10 Batch 3:  Loss:     1.0459 Accuracy: 0.545400\n",
      "Epoch 68, CIFAR-10 Batch 4:  Loss:     1.0722 Accuracy: 0.539800\n",
      "Epoch 68, CIFAR-10 Batch 5:  Loss:     1.1208 Accuracy: 0.539200\n",
      "Epoch 69, CIFAR-10 Batch 1:  Loss:     1.1589 Accuracy: 0.542200\n",
      "Epoch 69, CIFAR-10 Batch 2:  Loss:     1.0603 Accuracy: 0.534800\n",
      "Epoch 69, CIFAR-10 Batch 3:  Loss:     1.0572 Accuracy: 0.542800\n",
      "Epoch 69, CIFAR-10 Batch 4:  Loss:     1.0683 Accuracy: 0.546200\n",
      "Epoch 69, CIFAR-10 Batch 5:  Loss:     1.1110 Accuracy: 0.542800\n",
      "Epoch 70, CIFAR-10 Batch 1:  Loss:     1.1592 Accuracy: 0.544800\n",
      "Epoch 70, CIFAR-10 Batch 2:  Loss:     1.0628 Accuracy: 0.542000\n",
      "Epoch 70, CIFAR-10 Batch 3:  Loss:     1.0384 Accuracy: 0.548400\n",
      "Epoch 70, CIFAR-10 Batch 4:  Loss:     1.0667 Accuracy: 0.534600\n",
      "Epoch 70, CIFAR-10 Batch 5:  Loss:     1.1087 Accuracy: 0.541800\n",
      "Epoch 71, CIFAR-10 Batch 1:  Loss:     1.1533 Accuracy: 0.543200\n",
      "Epoch 71, CIFAR-10 Batch 2:  Loss:     1.0589 Accuracy: 0.542800\n",
      "Epoch 71, CIFAR-10 Batch 3:  Loss:     1.0373 Accuracy: 0.543000\n",
      "Epoch 71, CIFAR-10 Batch 4:  Loss:     1.0557 Accuracy: 0.544200\n",
      "Epoch 71, CIFAR-10 Batch 5:  Loss:     1.0998 Accuracy: 0.544400\n",
      "Epoch 72, CIFAR-10 Batch 1:  Loss:     1.1439 Accuracy: 0.543600\n",
      "Epoch 72, CIFAR-10 Batch 2:  Loss:     1.0564 Accuracy: 0.545200\n",
      "Epoch 72, CIFAR-10 Batch 3:  Loss:     1.0445 Accuracy: 0.545800\n",
      "Epoch 72, CIFAR-10 Batch 4:  Loss:     1.0620 Accuracy: 0.543000\n",
      "Epoch 72, CIFAR-10 Batch 5:  Loss:     1.1019 Accuracy: 0.548000\n",
      "Epoch 73, CIFAR-10 Batch 1:  Loss:     1.1433 Accuracy: 0.546600\n",
      "Epoch 73, CIFAR-10 Batch 2:  Loss:     1.0522 Accuracy: 0.546400\n",
      "Epoch 73, CIFAR-10 Batch 3:  Loss:     1.0340 Accuracy: 0.547200\n",
      "Epoch 73, CIFAR-10 Batch 4:  Loss:     1.0666 Accuracy: 0.537600\n",
      "Epoch 73, CIFAR-10 Batch 5:  Loss:     1.1015 Accuracy: 0.545800\n",
      "Epoch 74, CIFAR-10 Batch 1:  Loss:     1.1429 Accuracy: 0.544200\n",
      "Epoch 74, CIFAR-10 Batch 2:  Loss:     1.0580 Accuracy: 0.543200\n",
      "Epoch 74, CIFAR-10 Batch 3:  Loss:     1.0281 Accuracy: 0.546800\n",
      "Epoch 74, CIFAR-10 Batch 4:  Loss:     1.0438 Accuracy: 0.544200\n",
      "Epoch 74, CIFAR-10 Batch 5:  Loss:     1.0984 Accuracy: 0.550000\n",
      "Epoch 75, CIFAR-10 Batch 1:  Loss:     1.1455 Accuracy: 0.544800\n",
      "Epoch 75, CIFAR-10 Batch 2:  Loss:     1.0552 Accuracy: 0.543600\n",
      "Epoch 75, CIFAR-10 Batch 3:  Loss:     1.0381 Accuracy: 0.545600\n",
      "Epoch 75, CIFAR-10 Batch 4:  Loss:     1.0368 Accuracy: 0.540400\n",
      "Epoch 75, CIFAR-10 Batch 5:  Loss:     1.1013 Accuracy: 0.540000\n",
      "Epoch 76, CIFAR-10 Batch 1:  Loss:     1.1543 Accuracy: 0.541400\n",
      "Epoch 76, CIFAR-10 Batch 2:  Loss:     1.0662 Accuracy: 0.543400\n",
      "Epoch 76, CIFAR-10 Batch 3:  Loss:     1.0330 Accuracy: 0.541800\n",
      "Epoch 76, CIFAR-10 Batch 4:  Loss:     1.0620 Accuracy: 0.541800\n",
      "Epoch 76, CIFAR-10 Batch 5:  Loss:     1.0956 Accuracy: 0.546000\n",
      "Epoch 77, CIFAR-10 Batch 1:  Loss:     1.1407 Accuracy: 0.541400\n",
      "Epoch 77, CIFAR-10 Batch 2:  Loss:     1.0502 Accuracy: 0.539600\n",
      "Epoch 77, CIFAR-10 Batch 3:  Loss:     1.0261 Accuracy: 0.550000\n",
      "Epoch 77, CIFAR-10 Batch 4:  Loss:     1.0310 Accuracy: 0.543200\n",
      "Epoch 77, CIFAR-10 Batch 5:  Loss:     1.1023 Accuracy: 0.541200\n",
      "Epoch 78, CIFAR-10 Batch 1:  Loss:     1.1379 Accuracy: 0.546600\n",
      "Epoch 78, CIFAR-10 Batch 2:  Loss:     1.0423 Accuracy: 0.546000\n",
      "Epoch 78, CIFAR-10 Batch 3:  Loss:     1.0199 Accuracy: 0.545200\n",
      "Epoch 78, CIFAR-10 Batch 4:  Loss:     1.0425 Accuracy: 0.544000\n",
      "Epoch 78, CIFAR-10 Batch 5:  Loss:     1.1001 Accuracy: 0.545000\n",
      "Epoch 79, CIFAR-10 Batch 1:  Loss:     1.1359 Accuracy: 0.546800\n",
      "Epoch 79, CIFAR-10 Batch 2:  Loss:     1.0578 Accuracy: 0.542400\n",
      "Epoch 79, CIFAR-10 Batch 3:  Loss:     1.0415 Accuracy: 0.546200\n",
      "Epoch 79, CIFAR-10 Batch 4:  Loss:     1.0493 Accuracy: 0.539200\n",
      "Epoch 79, CIFAR-10 Batch 5:  Loss:     1.0851 Accuracy: 0.544400\n",
      "Epoch 80, CIFAR-10 Batch 1:  Loss:     1.1401 Accuracy: 0.540000\n",
      "Epoch 80, CIFAR-10 Batch 2:  Loss:     1.0487 Accuracy: 0.543000\n",
      "Epoch 80, CIFAR-10 Batch 3:  Loss:     1.0267 Accuracy: 0.541200\n",
      "Epoch 80, CIFAR-10 Batch 4:  Loss:     1.0382 Accuracy: 0.542000\n",
      "Epoch 80, CIFAR-10 Batch 5:  Loss:     1.0895 Accuracy: 0.542600\n",
      "Epoch 81, CIFAR-10 Batch 1:  Loss:     1.1382 Accuracy: 0.543800\n",
      "Epoch 81, CIFAR-10 Batch 2:  Loss:     1.0319 Accuracy: 0.541800\n",
      "Epoch 81, CIFAR-10 Batch 3:  Loss:     1.0150 Accuracy: 0.545000\n",
      "Epoch 81, CIFAR-10 Batch 4:  Loss:     1.0338 Accuracy: 0.539600\n",
      "Epoch 81, CIFAR-10 Batch 5:  Loss:     1.0927 Accuracy: 0.542800\n",
      "Epoch 82, CIFAR-10 Batch 1:  Loss:     1.1342 Accuracy: 0.543600\n",
      "Epoch 82, CIFAR-10 Batch 2:  Loss:     1.0293 Accuracy: 0.545400\n",
      "Epoch 82, CIFAR-10 Batch 3:  Loss:     1.0149 Accuracy: 0.546600\n",
      "Epoch 82, CIFAR-10 Batch 4:  Loss:     1.0364 Accuracy: 0.545000\n",
      "Epoch 82, CIFAR-10 Batch 5:  Loss:     1.0904 Accuracy: 0.549600\n",
      "Epoch 83, CIFAR-10 Batch 1:  Loss:     1.1262 Accuracy: 0.544400\n",
      "Epoch 83, CIFAR-10 Batch 2:  Loss:     1.0279 Accuracy: 0.546400\n",
      "Epoch 83, CIFAR-10 Batch 3:  Loss:     1.0313 Accuracy: 0.539400\n",
      "Epoch 83, CIFAR-10 Batch 4:  Loss:     1.0345 Accuracy: 0.545000\n",
      "Epoch 83, CIFAR-10 Batch 5:  Loss:     1.0827 Accuracy: 0.549600\n",
      "Epoch 84, CIFAR-10 Batch 1:  Loss:     1.1297 Accuracy: 0.546000\n",
      "Epoch 84, CIFAR-10 Batch 2:  Loss:     1.0270 Accuracy: 0.545000\n",
      "Epoch 84, CIFAR-10 Batch 3:  Loss:     1.0114 Accuracy: 0.543600\n",
      "Epoch 84, CIFAR-10 Batch 4:  Loss:     1.0423 Accuracy: 0.544400\n",
      "Epoch 84, CIFAR-10 Batch 5:  Loss:     1.0943 Accuracy: 0.543800\n",
      "Epoch 85, CIFAR-10 Batch 1:  Loss:     1.1248 Accuracy: 0.545400\n",
      "Epoch 85, CIFAR-10 Batch 2:  Loss:     1.0231 Accuracy: 0.542200\n",
      "Epoch 85, CIFAR-10 Batch 3:  Loss:     1.0128 Accuracy: 0.549400\n",
      "Epoch 85, CIFAR-10 Batch 4:  Loss:     1.0351 Accuracy: 0.543800\n",
      "Epoch 85, CIFAR-10 Batch 5:  Loss:     1.0955 Accuracy: 0.541200\n",
      "Epoch 86, CIFAR-10 Batch 1:  Loss:     1.1275 Accuracy: 0.546600\n",
      "Epoch 86, CIFAR-10 Batch 2:  Loss:     1.0199 Accuracy: 0.540400\n",
      "Epoch 86, CIFAR-10 Batch 3:  Loss:     1.0236 Accuracy: 0.544000\n",
      "Epoch 86, CIFAR-10 Batch 4:  Loss:     1.0277 Accuracy: 0.540000\n",
      "Epoch 86, CIFAR-10 Batch 5:  Loss:     1.0781 Accuracy: 0.543000\n",
      "Epoch 87, CIFAR-10 Batch 1:  Loss:     1.1098 Accuracy: 0.546800\n",
      "Epoch 87, CIFAR-10 Batch 2:  Loss:     1.0201 Accuracy: 0.543800\n",
      "Epoch 87, CIFAR-10 Batch 3:  Loss:     1.0142 Accuracy: 0.545000\n",
      "Epoch 87, CIFAR-10 Batch 4:  Loss:     1.0213 Accuracy: 0.542000\n",
      "Epoch 87, CIFAR-10 Batch 5:  Loss:     1.0913 Accuracy: 0.546000\n",
      "Epoch 88, CIFAR-10 Batch 1:  Loss:     1.1183 Accuracy: 0.547200\n",
      "Epoch 88, CIFAR-10 Batch 2:  Loss:     1.0118 Accuracy: 0.550600\n",
      "Epoch 88, CIFAR-10 Batch 3:  Loss:     0.9998 Accuracy: 0.546600\n",
      "Epoch 88, CIFAR-10 Batch 4:  Loss:     1.0314 Accuracy: 0.539600\n",
      "Epoch 88, CIFAR-10 Batch 5:  Loss:     1.0919 Accuracy: 0.545800\n",
      "Epoch 89, CIFAR-10 Batch 1:  Loss:     1.1133 Accuracy: 0.546000\n",
      "Epoch 89, CIFAR-10 Batch 2:  Loss:     1.0166 Accuracy: 0.545200\n",
      "Epoch 89, CIFAR-10 Batch 3:  Loss:     1.0443 Accuracy: 0.544400\n",
      "Epoch 89, CIFAR-10 Batch 4:  Loss:     1.0255 Accuracy: 0.544600\n",
      "Epoch 89, CIFAR-10 Batch 5:  Loss:     1.0881 Accuracy: 0.548200\n",
      "Epoch 90, CIFAR-10 Batch 1:  Loss:     1.1040 Accuracy: 0.546200\n",
      "Epoch 90, CIFAR-10 Batch 2:  Loss:     1.0142 Accuracy: 0.544600\n",
      "Epoch 90, CIFAR-10 Batch 3:  Loss:     1.0001 Accuracy: 0.541200\n",
      "Epoch 90, CIFAR-10 Batch 4:  Loss:     1.0266 Accuracy: 0.547000\n",
      "Epoch 90, CIFAR-10 Batch 5:  Loss:     1.0925 Accuracy: 0.547400\n",
      "Epoch 91, CIFAR-10 Batch 1:  Loss:     1.1080 Accuracy: 0.548600\n",
      "Epoch 91, CIFAR-10 Batch 2:  Loss:     0.9998 Accuracy: 0.547000\n",
      "Epoch 91, CIFAR-10 Batch 3:  Loss:     1.0114 Accuracy: 0.546600\n",
      "Epoch 91, CIFAR-10 Batch 4:  Loss:     1.0285 Accuracy: 0.539400\n",
      "Epoch 91, CIFAR-10 Batch 5:  Loss:     1.0801 Accuracy: 0.548000\n",
      "Epoch 92, CIFAR-10 Batch 1:  Loss:     1.1092 Accuracy: 0.550400\n",
      "Epoch 92, CIFAR-10 Batch 2:  Loss:     1.0128 Accuracy: 0.547000\n",
      "Epoch 92, CIFAR-10 Batch 3:  Loss:     0.9975 Accuracy: 0.548000\n",
      "Epoch 92, CIFAR-10 Batch 4:  Loss:     1.0361 Accuracy: 0.543800\n",
      "Epoch 92, CIFAR-10 Batch 5:  Loss:     1.0807 Accuracy: 0.548400\n",
      "Epoch 93, CIFAR-10 Batch 1:  Loss:     1.1087 Accuracy: 0.546400\n",
      "Epoch 93, CIFAR-10 Batch 2:  Loss:     1.0051 Accuracy: 0.542400\n",
      "Epoch 93, CIFAR-10 Batch 3:  Loss:     1.0121 Accuracy: 0.548000\n",
      "Epoch 93, CIFAR-10 Batch 4:  Loss:     1.0318 Accuracy: 0.538000\n",
      "Epoch 93, CIFAR-10 Batch 5:  Loss:     1.0682 Accuracy: 0.550200\n",
      "Epoch 94, CIFAR-10 Batch 1:  Loss:     1.1013 Accuracy: 0.546800\n",
      "Epoch 94, CIFAR-10 Batch 2:  Loss:     1.0018 Accuracy: 0.548600\n",
      "Epoch 94, CIFAR-10 Batch 3:  Loss:     1.0058 Accuracy: 0.549200\n",
      "Epoch 94, CIFAR-10 Batch 4:  Loss:     1.0415 Accuracy: 0.542800\n",
      "Epoch 94, CIFAR-10 Batch 5:  Loss:     1.0724 Accuracy: 0.550000\n",
      "Epoch 95, CIFAR-10 Batch 1:  Loss:     1.1123 Accuracy: 0.546200\n",
      "Epoch 95, CIFAR-10 Batch 2:  Loss:     0.9974 Accuracy: 0.545200\n",
      "Epoch 95, CIFAR-10 Batch 3:  Loss:     1.0003 Accuracy: 0.544800\n",
      "Epoch 95, CIFAR-10 Batch 4:  Loss:     1.0210 Accuracy: 0.540400\n",
      "Epoch 95, CIFAR-10 Batch 5:  Loss:     1.0651 Accuracy: 0.548600\n",
      "Epoch 96, CIFAR-10 Batch 1:  Loss:     1.1050 Accuracy: 0.545000\n",
      "Epoch 96, CIFAR-10 Batch 2:  Loss:     1.0006 Accuracy: 0.544200\n",
      "Epoch 96, CIFAR-10 Batch 3:  Loss:     1.0193 Accuracy: 0.541200\n",
      "Epoch 96, CIFAR-10 Batch 4:  Loss:     1.0357 Accuracy: 0.547200\n",
      "Epoch 96, CIFAR-10 Batch 5:  Loss:     1.0613 Accuracy: 0.549600\n",
      "Epoch 97, CIFAR-10 Batch 1:  Loss:     1.1040 Accuracy: 0.548800\n",
      "Epoch 97, CIFAR-10 Batch 2:  Loss:     0.9994 Accuracy: 0.542600\n",
      "Epoch 97, CIFAR-10 Batch 3:  Loss:     1.0029 Accuracy: 0.542400\n",
      "Epoch 97, CIFAR-10 Batch 4:  Loss:     1.0361 Accuracy: 0.543800\n",
      "Epoch 97, CIFAR-10 Batch 5:  Loss:     1.0707 Accuracy: 0.548600\n",
      "Epoch 98, CIFAR-10 Batch 1:  Loss:     1.0916 Accuracy: 0.548800\n",
      "Epoch 98, CIFAR-10 Batch 2:  Loss:     1.0005 Accuracy: 0.543200\n",
      "Epoch 98, CIFAR-10 Batch 3:  Loss:     0.9898 Accuracy: 0.545200\n",
      "Epoch 98, CIFAR-10 Batch 4:  Loss:     1.0181 Accuracy: 0.540000\n",
      "Epoch 98, CIFAR-10 Batch 5:  Loss:     1.0692 Accuracy: 0.549200\n",
      "Epoch 99, CIFAR-10 Batch 1:  Loss:     1.0921 Accuracy: 0.550200\n",
      "Epoch 99, CIFAR-10 Batch 2:  Loss:     0.9971 Accuracy: 0.549000\n",
      "Epoch 99, CIFAR-10 Batch 3:  Loss:     0.9831 Accuracy: 0.544000\n",
      "Epoch 99, CIFAR-10 Batch 4:  Loss:     1.0024 Accuracy: 0.542200\n",
      "Epoch 99, CIFAR-10 Batch 5:  Loss:     1.0714 Accuracy: 0.549800\n",
      "Epoch 100, CIFAR-10 Batch 1:  Loss:     1.0963 Accuracy: 0.550400\n",
      "Epoch 100, CIFAR-10 Batch 2:  Loss:     0.9919 Accuracy: 0.545200\n",
      "Epoch 100, CIFAR-10 Batch 3:  Loss:     0.9887 Accuracy: 0.546400\n",
      "Epoch 100, CIFAR-10 Batch 4:  Loss:     1.0034 Accuracy: 0.544600\n",
      "Epoch 100, CIFAR-10 Batch 5:  Loss:     1.0679 Accuracy: 0.547400\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.5465590536594391\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHIuIiIiIRP8HNqjliKgAbFYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc694541828>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
